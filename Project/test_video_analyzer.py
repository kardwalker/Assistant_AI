"""
Test Script for Video Analysis: VLM vs Basic Computer Vision
Compares Vision Language Models (VLM) with traditional computer vision approaches
"""
import os
import sys
import time

# Add current directory to path for imports
sys.path.append(os.path.dirname(__file__))

def test_vlm_vs_basic_cv():
    """Compare VLM (Vision Language Models) vs Basic Computer Vision"""
    
    # Video file path
    video_path = "C:\\Users\\Aman\\Desktop\\Virtual__house\\Vuencode_AI_Hackthon\\Vuenagent\\WhatsApp Video 2024-04-10 at 16.41.51_71572a51.mp4"
    
    print("ğŸ”¬ HYBRID ANALYSIS: VLM + BASIC CV PERFORMANCE COMPARISON")
    print("="*70)
    
    try:
        from video_analyzer import VideoContentAnalyzer, analyze_video_only, HybridAnalysisResult
        
        # Test 1: Hybrid Analysis (RECOMMENDED APPROACH)
        print("\nğŸš€ HYBRID ANALYSIS (Smart Basic CV + VLM)")
        print("-" * 60)
        print("ğŸ“Š Features:")
        print("   â€¢ Fast Basic CV analysis first (3-5 seconds)")
        print("   â€¢ Intelligent VLM enhancement when beneficial")
        print("   â€¢ Merged results for best accuracy")
        print("   â€¢ Automatic cost optimization")
        
        import time
        start_time = time.time()
        
        # Create hybrid analyzer (supports both local and API VLM)
        hybrid_analyzer = VideoContentAnalyzer(use_ai_model=True, use_api=False)  # Use local VLM
        hybrid_result = hybrid_analyzer.analyze_video_content_hybrid(video_path)
        
        total_time = time.time() - start_time
        
        print(f"\nğŸ“ˆ HYBRID RESULTS:")
        print(f"â±ï¸ Total Processing Time: {total_time:.2f} seconds")
        print(f"ğŸ¯ Final Analysis Method: {hybrid_result.merged_result.analysis_method}")
        print(f"ğŸ“Š Confidence Score: {hybrid_result.merged_result.confidence_score:.1f}/1.0")
        print(f"âœ… Success: {hybrid_result.merged_result.success}")
        
        print(f"\nğŸ” MERGED ANALYSIS:")
        print(f"ğŸ“¹ Duration: {hybrid_result.merged_result.duration:.1f}s")
        print(f"ğŸ–¼ï¸ Frames Analyzed: {len(hybrid_result.merged_result.frame_descriptions)}")
        print(f"ğŸ¬ Scene: {hybrid_result.merged_result.scene_summary}")
        print(f"ğŸ” Objects: {', '.join(hybrid_result.merged_result.key_objects)}")
        
        print(f"\nâš¡ PERFORMANCE BREAKDOWN:")
        metrics = hybrid_result.performance_metrics
        print(f"Basic CV Time: {metrics['basic_cv_time']:.2f}s")
        print(f"VLM Time: {metrics['vlm_time']:.2f}s")
        print(f"Used VLM Enhancement: {'âœ… Yes' if metrics['used_vlm'] else 'âŒ No'}")
        print(f"Confidence Improvement: {metrics['confidence_improvement']:.1%}")
        print(f"Analysis Depth Factor: {metrics['speedup_factor']:.1f}x")
        
        # Compare individual results
        print(f"\nğŸ“‹ DETAILED COMPARISON:")
        print("-" * 60)
        print(f"ğŸ”§ BASIC CV ALONE:")
        print(f"   Time: {hybrid_result.basic_result.processing_time:.2f}s")
        print(f"   Objects: {len(hybrid_result.basic_result.key_objects)} found")
        print(f"   Summary: {hybrid_result.basic_result.scene_summary[:80]}...")
        
        if hybrid_result.vlm_result:
            print(f"\nğŸ¤– VLM ENHANCEMENT:")
            print(f"   Time: {hybrid_result.vlm_result.processing_time:.2f}s")
            print(f"   Objects: {len(hybrid_result.vlm_result.key_objects)} found")
            print(f"   Summary: {hybrid_result.vlm_result.scene_summary[:80]}...")
        else:
            print(f"\nğŸ¤– VLM ENHANCEMENT: Skipped (Basic CV was sufficient)")
        
        # Test 2: Compare with pure methods for reference
        print(f"\nğŸ“Š REFERENCE COMPARISON (Individual Methods)")
        print("-" * 60)
        
        # Basic CV only
        print("ğŸ”§ Pure Basic CV:")
        start_time = time.time()
        basic_only = VideoContentAnalyzer(use_ai_model=False, use_api=False)
        basic_result = basic_only.analyze_video_content(video_path)
        basic_time = time.time() - start_time
        print(f"   â±ï¸ Time: {basic_time:.2f}s | Objects: {len(basic_result.key_objects)} | Success: {basic_result.success}")
        
        # VLM only (if available)
        if hybrid_analyzer.use_ai_model or hybrid_analyzer.use_api:
            print("ğŸ¤– Pure VLM:")
            start_time = time.time()
            vlm_only = VideoContentAnalyzer(use_ai_model=True, use_api=False)
            vlm_result = vlm_only.analyze_video_content(video_path)
            vlm_time = time.time() - start_time
            print(f"   â±ï¸ Time: {vlm_time:.2f}s | Objects: {len(vlm_result.key_objects)} | Success: {vlm_result.success}")
        
        print(f"\nğŸ¯ HYBRID ADVANTAGE:")
        print("-" * 60)
        print("âœ… Gets speed of Basic CV + accuracy of VLM")
        print("âœ… Automatically chooses best approach per video")
        print("âœ… Optimizes cost by avoiding unnecessary VLM calls")
        print("âœ… Merges results for comprehensive analysis")
        print("âœ… Maintains high confidence with smart fallbacks")
        
    except ImportError as e:
        print(f"âŒ Import error: {e}")
        print("Make sure video_analyzer.py is in the current directory")
    except Exception as e:
        print(f"âŒ Unexpected error: {e}")
        import traceback
        traceback.print_exc()
    
    print("\n" + "="*70)
    print("ğŸ Hybrid Analysis Comparison Completed!")
    
    print("\nğŸ’¡ HYBRID RECOMMENDATION:")
    print("   ğŸš€ Use hybrid analysis for production systems")
    print("   âš¡ Fast initial results + enhanced quality when needed")
    print("   ğŸ’° Cost-effective with intelligent VLM usage")
    print("   ğŸ¯ Best balance of speed, accuracy, and cost")
    
    try:
        from video_analyzer import VideoContentAnalyzer, analyze_video_only
        
        # Test 1: Basic Computer Vision (Traditional CV)
        print("\nğŸ”§ BASIC COMPUTER VISION (Traditional CV)")
        print("-" * 50)
        print("ğŸ“Š Capabilities:")
        print("   â€¢ Edge detection, color analysis, brightness")
        print("   â€¢ Statistical analysis of pixel patterns")
        print("   â€¢ Motion detection, complexity analysis")
        print("   â€¢ Fast, deterministic, no internet required")
        
        start_time = time.time()
        analyzer_basic = VideoContentAnalyzer(use_ai_model=False, use_api=False)
        result_basic = analyzer_basic.analyze_video_content(video_path)
        basic_time = time.time() - start_time
        
        print(f"\nâ±ï¸ Processing Time: {basic_time:.2f} seconds")
        if result_basic.success:
            print(f"âœ… Analysis successful!")
            print(f"ğŸ“¹ Duration: {result_basic.duration:.1f}s")
            print(f"ğŸ–¼ï¸ Frames: {len(result_basic.frame_descriptions)}")
            print(f"ğŸ¬ Scene: {result_basic.scene_summary[:100]}...")
            print(f"ğŸ” Objects: {', '.join(result_basic.key_objects) if result_basic.key_objects else 'Basic patterns detected'}")
            print(f"ğŸ’° Cost: FREE")
        
        # Test 2: VLM Analysis (Local AI Models)
        print("\nğŸ¤– VLM - LOCAL AI MODELS (BLIP, etc.)")
        print("-" * 50)
        print("ğŸ“Š Capabilities:")
        print("   â€¢ Natural language scene descriptions")
        print("   â€¢ Object recognition and naming")
        print("   â€¢ Context understanding, relationships")
        print("   â€¢ Semantic understanding of scenes")
        
        start_time = time.time()
        analyzer_local_ai = VideoContentAnalyzer(use_ai_model=True, use_api=False)
        if analyzer_local_ai.use_ai_model:
            result_local_ai = analyzer_local_ai.analyze_video_content(video_path)
            local_ai_time = time.time() - start_time
            
            print(f"\nâ±ï¸ Processing Time: {local_ai_time:.2f} seconds")
            if result_local_ai.success:
                print(f"âœ… VLM analysis successful!")
                print(f"ğŸ¬ Scene: {result_local_ai.scene_summary[:120]}...")
                print(f"ğŸ” Objects: {', '.join(result_local_ai.key_objects)}")
                print(f"ğŸ’° Cost: FREE (after 990MB download)")
                print(f"ğŸ“¶ Internet: Not required after download")
            else:
                print(f"âŒ VLM analysis failed")
        else:
            print("âš ï¸ Local VLM models not available")
            print("ğŸ’¡ Models would need to be downloaded first")
        
        # Test 3: VLM via API (GPT-4 Vision, etc.)
        print("\nğŸŒ VLM - API SERVICES (GPT-4 Vision, etc.)")
        print("-" * 50)
        print("ğŸ“Š Capabilities:")
        print("   â€¢ State-of-the-art vision understanding")
        print("   â€¢ Complex reasoning about visual content")
        print("   â€¢ Multi-modal analysis (vision + language)")
        print("   â€¢ Constantly improving models")
        
        analyzer_api = VideoContentAnalyzer(use_ai_model=True, use_api=True)
        
        if analyzer_api.use_api:
            print("âœ… API keys found - VLM API available")
            start_time = time.time()
            result_api = analyzer_api.analyze_video_content(video_path)
            api_time = time.time() - start_time
            
            print(f"â±ï¸ Processing Time: {api_time:.2f} seconds")
            if result_api.success:
                print(f"ğŸ¬ Scene: {result_api.scene_summary[:120]}...")
                print(f"ğŸ’° Cost: ~$0.01-0.10 per video (varies by frames)")
                print(f"ğŸ“¶ Internet: Required")
            else:
                print(f"âŒ API analysis failed")
        else:
            print("âš ï¸ No API keys found - VLM API analysis skipped")
            print("ğŸ’¡ To enable VLM API analysis:")
            print("   1. Set OPENAI_API_KEY for GPT-4 Vision")
            print("   2. Or set AZURE_API_KEY + AZURE_ENDPOINT")
        
        # Comparison Summary
        print("\nğŸ“Š COMPREHENSIVE COMPARISON")
        print("="*60)
        print("| Method            | Speed    | Accuracy | Cost      | Internet |")
        print("|-------------------|----------|----------|-----------|----------|")
        print("| Basic CV          | Fast     | Basic    | FREE      | No       |")
        print("| Local VLM         | Medium   | High     | FREE*     | No       |")
        print("| API VLM           | Fast     | Highest  | Pay/Use   | Yes      |")
        print("*After initial model download")
        
        print("\nğŸ¯ WHEN TO USE EACH APPROACH:")
        print("-" * 60)
        print("ğŸ”§ BASIC COMPUTER VISION:")
        print("   âœ… Quick prototyping and testing")
        print("   âœ… Real-time processing requirements")
        print("   âœ… Limited budget or offline scenarios")
        print("   âœ… Simple pattern detection tasks")
        print("   âŒ Limited semantic understanding")
        
        print("\nğŸ¤– LOCAL VLM MODELS:")
        print("   âœ… Good balance of accuracy and cost")
        print("   âœ… Privacy-sensitive applications")
        print("   âœ… Offline deployment requirements")
        print("   âœ… Batch processing scenarios")
        print("   âŒ Initial setup complexity")
        print("   âŒ Large storage requirements")
        
        print("\nğŸŒ API VLM SERVICES:")
        print("   âœ… Highest accuracy and capabilities")
        print("   âœ… Latest model improvements")
        print("   âœ… No local storage requirements")
        print("   âœ… Complex reasoning tasks")
        print("   âŒ Ongoing costs")
        print("   âŒ Internet dependency")
        
        print("\nğŸš€ FUTURE TRENDS:")
        print("-" * 60)
        print("ğŸ“ˆ VLMs are rapidly improving but:")
        print("   â€¢ Basic CV still valuable for speed/efficiency")
        print("   â€¢ Hybrid approaches often work best")
        print("   â€¢ Edge computing favors lightweight CV")
        print("   â€¢ Cost considerations matter at scale")
        print("   â€¢ Privacy requirements favor local processing")
        
        print("\nğŸ’¡ RECOMMENDATION FOR YOUR PROJECT:")
        print("-" * 60)
        print("ğŸ¯ Use a HYBRID APPROACH:")
        print("   1. Basic CV for real-time preview/filtering")
        print("   2. Local VLM for detailed analysis")
        print("   3. API VLM for critical/complex content")
        print("   4. Let users choose based on their needs")
        
    except ImportError as e:
        print(f"âŒ Import error: {e}")
        print("Make sure video_analyzer.py is in the current directory")
    except Exception as e:
        print(f"âŒ Unexpected error: {e}")
        import traceback
        traceback.print_exc()
    
    print("\n" + "="*60)
    print("ğŸ VLM vs Basic CV Comparison Completed!")

if __name__ == "__main__":
    test_vlm_vs_basic_cv()
        analyzer_basic = VideoContentAnalyzer(use_ai_model=False, use_api=False)
        result_basic = analyzer_basic.analyze_video_content(video_path)
        
        if result_basic.success:
            print(f"âœ… Basic analysis successful!")
            print(f"Duration: {result_basic.duration:.1f}s")
            print(f"Frames analyzed: {len(result_basic.frame_descriptions)}")
            print(f"Scene summary: {result_basic.scene_summary}")
            print(f"Key objects: {', '.join(result_basic.key_objects)}")
        else:
            print(f"âŒ Basic analysis failed: {result_basic.scene_summary}")
        
        # Test 2: API-based analysis (if keys available)
        print("\nğŸš€ Test 2: API-based Analysis")
        print("-" * 40)
        analyzer_api = VideoContentAnalyzer(use_ai_model=True, use_api=True)
        
        if analyzer_api.use_api:
            print("âœ… API keys found - using fast API analysis")
            result_api = analyzer_api.analyze_video_content(video_path)
            if result_api.success:
                print(f"Duration: {result_api.duration:.1f}s")
                print(f"Scene summary: {result_api.scene_summary}")
            else:
                print(f"âŒ API analysis failed: {result_api.scene_summary}")
        else:
            print("âš ï¸ No API keys found - API analysis skipped")
            print("ğŸ’¡ To enable API analysis:")
            print("   1. Set OPENAI_API_KEY environment variable")
            print("   2. Or set AZURE_API_KEY + AZURE_ENDPOINT")
        
        # Test 3: Standalone video analysis function
        print("\nğŸ“¹ Test 3: Standalone Video Analysis Function")
        print("-" * 40)
        standalone_result = analyze_video_only(video_path)
        
        if standalone_result['success']:
            print(f"âœ… Standalone analysis successful!")
            print(f"Method: {standalone_result.get('analysis_method', 'Unknown')}")
            print(f"Duration: {standalone_result['duration']:.1f}s")
            print(f"Scene summary: {standalone_result['scene_summary']}")
        else:
            print(f"âŒ Standalone analysis failed: {standalone_result.get('error', 'Unknown error')}")
        
    except ImportError as e:
        print(f"âŒ Import error: {e}")
        print("Make sure video_analyzer.py is in the current directory")
    except Exception as e:
        print(f"âŒ Unexpected error: {e}")
        import traceback
        traceback.print_exc()
    
    print("\n" + "="*50)
    print("ğŸ Testing completed!")
    
    # Performance recommendations
    print("\nğŸ’¡ Performance Recommendations:")
    print("   ğŸš€ FASTEST: Use API keys (OpenAI/Azure) - instant results")
    print("   ğŸ”§ MEDIUM: Basic computer vision - no downloads, good results")
    print("   â³ SLOWEST: Local AI models - 990MB download, high accuracy")

if __name__ == "__main__":
    test_video_analysis()
